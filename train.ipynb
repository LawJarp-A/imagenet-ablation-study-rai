{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T17:43:17.930184Z","iopub.status.busy":"2024-05-06T17:43:17.929841Z","iopub.status.idle":"2024-05-06T17:43:30.229241Z","shell.execute_reply":"2024-05-06T17:43:30.228422Z","shell.execute_reply.started":"2024-05-06T17:43:17.930145Z"},"trusted":true},"outputs":[],"source":["import os\n","import json\n","from PIL import Image\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, random_split\n","from torch.cuda.amp import autocast, GradScaler\n","from torch.optim.lr_scheduler import OneCycleLR\n","\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","import timm\n","\n","import wandb\n","import pytorch_lightning as pl\n","from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateFinder\n","from torchmetrics import Accuracy\n"]},{"cell_type":"markdown","metadata":{},"source":["## Consolidate data"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T17:43:30.231586Z","iopub.status.busy":"2024-05-06T17:43:30.231135Z","iopub.status.idle":"2024-05-06T17:43:30.238294Z","shell.execute_reply":"2024-05-06T17:43:30.237332Z","shell.execute_reply.started":"2024-05-06T17:43:30.231553Z"},"trusted":true},"outputs":[],"source":["def create_dataframe_from_folders(folder_list):\n","    data = {'image_path': [], 'class': []}\n","\n","    for folder in tqdm(folder_list):\n","        for root, dirs, files in os.walk(folder):\n","            for file in files:\n","                if file.endswith('.JPEG'):\n","                    ts_file_path = os.path.join(root, file)\n","                    data['image_path'].append(ts_file_path)\n","                    data['class'].append(os.path.basename(root))\n","\n","    df = pd.DataFrame(data)\n","    return df"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T17:43:30.239850Z","iopub.status.busy":"2024-05-06T17:43:30.239473Z","iopub.status.idle":"2024-05-06T17:45:05.255283Z","shell.execute_reply":"2024-05-06T17:45:05.254001Z","shell.execute_reply.started":"2024-05-06T17:43:30.239817Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 4/4 [01:33<00:00, 23.36s/it]\n","100%|██████████| 1/1 [00:01<00:00,  1.53s/it]"]},{"name":"stdout","output_type":"stream","text":["Number of Training Samples 130000\n","Number of unique clases:  100\n","\n","Number of Validation Samples 5000\n","CPU times: user 950 ms, sys: 1.25 s, total: 2.2 s\n","Wall time: 1min 35s\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["%%time\n","train_df = create_dataframe_from_folders(['/kaggle/input/imagenet100/train.X1', '/kaggle/input/imagenet100/train.X2', '/kaggle/input/imagenet100/train.X3', '/kaggle/input/imagenet100/train.X4'])\n","val_df = create_dataframe_from_folders(['/kaggle/input/imagenet100/val.X'])\n","print('Number of Training Samples', len(train_df))\n","print('Number of unique clases: ', train_df['class'].nunique())\n","print()\n","print('Number of Validation Samples', len(val_df))"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T17:45:05.257824Z","iopub.status.busy":"2024-05-06T17:45:05.257535Z","iopub.status.idle":"2024-05-06T17:45:05.271490Z","shell.execute_reply":"2024-05-06T17:45:05.270582Z","shell.execute_reply.started":"2024-05-06T17:45:05.257798Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_path</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/kaggle/input/imagenet100/train.X1/n01531178/n...</td>\n","      <td>n01531178</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/kaggle/input/imagenet100/train.X1/n01531178/n...</td>\n","      <td>n01531178</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/kaggle/input/imagenet100/train.X1/n01531178/n...</td>\n","      <td>n01531178</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/kaggle/input/imagenet100/train.X1/n01531178/n...</td>\n","      <td>n01531178</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/kaggle/input/imagenet100/train.X1/n01531178/n...</td>\n","      <td>n01531178</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                          image_path      class\n","0  /kaggle/input/imagenet100/train.X1/n01531178/n...  n01531178\n","1  /kaggle/input/imagenet100/train.X1/n01531178/n...  n01531178\n","2  /kaggle/input/imagenet100/train.X1/n01531178/n...  n01531178\n","3  /kaggle/input/imagenet100/train.X1/n01531178/n...  n01531178\n","4  /kaggle/input/imagenet100/train.X1/n01531178/n...  n01531178"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["train_df.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T17:45:05.273006Z","iopub.status.busy":"2024-05-06T17:45:05.272665Z","iopub.status.idle":"2024-05-06T17:45:05.282281Z","shell.execute_reply":"2024-05-06T17:45:05.281345Z","shell.execute_reply.started":"2024-05-06T17:45:05.272975Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_path</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/kaggle/input/imagenet100/val.X/n01531178/ILSV...</td>\n","      <td>n01531178</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/kaggle/input/imagenet100/val.X/n01531178/ILSV...</td>\n","      <td>n01531178</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/kaggle/input/imagenet100/val.X/n01531178/ILSV...</td>\n","      <td>n01531178</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/kaggle/input/imagenet100/val.X/n01531178/ILSV...</td>\n","      <td>n01531178</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/kaggle/input/imagenet100/val.X/n01531178/ILSV...</td>\n","      <td>n01531178</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                          image_path      class\n","0  /kaggle/input/imagenet100/val.X/n01531178/ILSV...  n01531178\n","1  /kaggle/input/imagenet100/val.X/n01531178/ILSV...  n01531178\n","2  /kaggle/input/imagenet100/val.X/n01531178/ILSV...  n01531178\n","3  /kaggle/input/imagenet100/val.X/n01531178/ILSV...  n01531178\n","4  /kaggle/input/imagenet100/val.X/n01531178/ILSV...  n01531178"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["val_df.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T17:45:05.283622Z","iopub.status.busy":"2024-05-06T17:45:05.283315Z","iopub.status.idle":"2024-05-06T17:45:05.300952Z","shell.execute_reply":"2024-05-06T17:45:05.300191Z","shell.execute_reply.started":"2024-05-06T17:45:05.283593Z"},"trusted":true},"outputs":[],"source":["class_to_label = {class_name: label for label, class_name in enumerate(train_df['class'].unique())}\n","label_to_class = {label: class_name for class_name, label in class_to_label.items()}"]},{"cell_type":"markdown","metadata":{},"source":["## Define Augmentations"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T17:45:05.302280Z","iopub.status.busy":"2024-05-06T17:45:05.302001Z","iopub.status.idle":"2024-05-06T17:45:05.330497Z","shell.execute_reply":"2024-05-06T17:45:05.329616Z","shell.execute_reply.started":"2024-05-06T17:45:05.302258Z"},"trusted":true},"outputs":[],"source":["hyp = {\n","    'image_size': 224,\n","    'batch_size': 128,\n","    'epochs': 15, \n","    'arch': 'mobilenetv2_100',\n","    'num_classes': 100,\n","    'early_stopping_patience': 7,\n","    'device': torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","}"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T17:45:05.331725Z","iopub.status.busy":"2024-05-06T17:45:05.331491Z","iopub.status.idle":"2024-05-06T17:45:05.339418Z","shell.execute_reply":"2024-05-06T17:45:05.338531Z","shell.execute_reply.started":"2024-05-06T17:45:05.331705Z"},"trusted":true},"outputs":[],"source":["# Define a set of augmentations for training\n","train_transform = A.Compose([\n","    A.Resize(224,224),  # Resize images to a common size\n","    A.HorizontalFlip(p=0.5),  # Apply horizontal flip with a probability of 0.5\n","    A.VerticalFlip(p=0.5),  # Apply vertical flip with a probability of 0.5\n","    A.RandomRotate90(p=0.5),  # Randomly rotate the image by 90 degrees\n","    A.RandomBrightnessContrast(p=0.2),  # Adjust brightness and contrast\n","    A.GaussNoise(p=0.2),  # Add random Gaussian noise\n","    A.Normalize(),  # Normalize pixel values to be in the range [0, 1]\n","    ToTensorV2(),  # Convert the image to a PyTorch tensor\n","])\n","\n","# Define augmentations for validation (usually only basic augmentations without randomness)\n","val_transform = A.Compose([\n","    A.Resize(224,224),\n","    A.Normalize(),\n","    ToTensorV2(),\n","])"]},{"cell_type":"markdown","metadata":{},"source":["## Define PyTorch Dataset"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T17:45:05.340717Z","iopub.status.busy":"2024-05-06T17:45:05.340485Z","iopub.status.idle":"2024-05-06T17:45:05.349842Z","shell.execute_reply":"2024-05-06T17:45:05.349039Z","shell.execute_reply.started":"2024-05-06T17:45:05.340696Z"},"trusted":true},"outputs":[],"source":["class CustomImageNetDataset(torch.utils.data.Dataset):\n","    def __init__(self, df, transform=None):\n","        self.data = df\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img_name = self.data.iloc[idx, 0]\n","        image = Image.open(img_name)\n","        image = image.convert('RGB')\n","        label = self.data.iloc[idx, 1]\n","        label = class_to_label[label]\n","        \n","        if self.transform:\n","            image = self.transform(image=np.array(image))['image']\n","\n","        return image, label\n"]},{"cell_type":"markdown","metadata":{},"source":["## Define Model"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T17:45:05.354389Z","iopub.status.busy":"2024-05-06T17:45:05.354085Z","iopub.status.idle":"2024-05-06T17:45:05.361869Z","shell.execute_reply":"2024-05-06T17:45:05.360955Z","shell.execute_reply.started":"2024-05-06T17:45:05.354366Z"},"trusted":true},"outputs":[],"source":["import torch.nn.functional as F\n","\n","class CustomModel(nn.Module):\n","    def __init__(self, model_name, num_classes, pretrained=True):\n","        super(CustomModel, self).__init__()\n","        # Load the base model\n","        self.base_model = timm.create_model(model_name, pretrained=pretrained, num_classes=0)\n","        \n","        # Modify the classification head\n","        in_features = self.base_model.num_features\n","        self.classifier = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(512, num_classes),\n","            nn.Softmax(dim=1)  # Apply softmax activation along the class dimension\n","        )\n","\n","    def forward(self, x):\n","        # Forward pass through the base model\n","        features = self.base_model(x)\n","        \n","        # Forward pass through the classifier\n","        output = self.classifier(features)\n","        \n","        return output"]},{"cell_type":"markdown","metadata":{},"source":["## Ready the data"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T17:45:05.363127Z","iopub.status.busy":"2024-05-06T17:45:05.362848Z","iopub.status.idle":"2024-05-06T17:45:05.375322Z","shell.execute_reply":"2024-05-06T17:45:05.374489Z","shell.execute_reply.started":"2024-05-06T17:45:05.363105Z"},"trusted":true},"outputs":[],"source":["train_dataset = CustomImageNetDataset(train_df, transform=train_transform)\n","val_dataset = CustomImageNetDataset(val_df, transform=val_transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=hyp['batch_size'], shuffle=True, num_workers=4, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=hyp['batch_size'], shuffle=False, num_workers=4, pin_memory=True)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T17:45:05.376614Z","iopub.status.busy":"2024-05-06T17:45:05.376304Z","iopub.status.idle":"2024-05-06T17:45:13.091297Z","shell.execute_reply":"2024-05-06T17:45:13.090131Z","shell.execute_reply.started":"2024-05-06T17:45:05.376591Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train DataLoader Sanity Check:\n","Batch 1:\n","Image shape: torch.Size([128, 3, 224, 224])\n","Label shape: torch.Size([128])\n","\n","\n","Batch 2:\n","Image shape: torch.Size([128, 3, 224, 224])\n","Label shape: torch.Size([128])\n","\n","\n","Batch 3:\n","Image shape: torch.Size([128, 3, 224, 224])\n","Label shape: torch.Size([128])\n","\n","\n","Validation DataLoader Sanity Check:\n","Batch 1:\n","Image shape: torch.Size([128, 3, 224, 224])\n","Label shape: torch.Size([128])\n","\n","\n","Batch 2:\n","Image shape: torch.Size([128, 3, 224, 224])\n","Label shape: torch.Size([128])\n","\n","\n","Batch 3:\n","Image shape: torch.Size([128, 3, 224, 224])\n","Label shape: torch.Size([128])\n","\n","\n"]}],"source":["# Perform a sanity check on the data loaders\n","def check_data_loader(loader):\n","    for batch_idx, (images, labels) in enumerate(loader):\n","        print(f\"Batch {batch_idx + 1}:\")\n","        print(\"Image shape:\", images.shape)\n","        print(\"Label shape:\", labels.shape)\n","        print(\"\\n\")\n","        \n","        # Stop after printing a few batches\n","        if batch_idx == 2:\n","            break\n","\n","# Perform sanity check on train_loader\n","print(\"Train DataLoader Sanity Check:\")\n","check_data_loader(train_loader)\n","\n","# Perform sanity check on val_loader\n","print(\"Validation DataLoader Sanity Check:\")\n","check_data_loader(val_loader)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Train with PyTorch Lightning"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T17:45:13.093023Z","iopub.status.busy":"2024-05-06T17:45:13.092710Z","iopub.status.idle":"2024-05-06T17:45:13.104951Z","shell.execute_reply":"2024-05-06T17:45:13.103987Z","shell.execute_reply.started":"2024-05-06T17:45:13.092994Z"},"trusted":true},"outputs":[],"source":["class PLModel(pl.LightningModule):\n","    def __init__(self, name, num_classes, learning_rate=1e-3):\n","        super().__init__()\n","        self.name = name\n","        self.num_classes = num_classes\n","        self.learning_rate = learning_rate\n","        \n","        # Define your model\n","        self.model = CustomModel(name, num_classes) # You need to define your model here\n","        \n","        # Loss function\n","        self.loss_fn = nn.CrossEntropyLoss()\n","        \n","        # Metrics\n","        self.train_acc = Accuracy('multiclass', num_classes=num_classes)\n","        self.valid_acc = Accuracy('multiclass', num_classes=num_classes)\n","        \n","    def forward(self, x):\n","        return self.model(x)\n","    \n","    def configure_optimizers(self):\n","            optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n","            scheduler = OneCycleLR(optimizer, max_lr=self.learning_rate, steps_per_epoch=len(train_loader), epochs=self.trainer.max_epochs)\n","            return {\n","                'optimizer': optimizer,\n","#                 'lr_scheduler': {\n","#                     'scheduler': scheduler,\n","#                     'interval': 'step'\n","#                 }\n","            }\n","\n","    \n","    def training_step(self, batch, batch_idx):\n","        x, y = batch\n","        logits = self(x)\n","        loss = self.loss_fn(logits, y)\n","        self.log('train_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n","        self.log('train_acc', self.train_acc(logits, y), on_epoch=True, logger=True)\n","        return loss\n","    \n","    def validation_step(self, batch, batch_idx):\n","        x, y = batch\n","        logits = self(x)\n","        loss = self.loss_fn(logits, y)\n","        self.log('val_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n","        self.log('val_acc', self.valid_acc(logits, y), on_epoch=True, logger=True)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T17:45:13.106344Z","iopub.status.busy":"2024-05-06T17:45:13.106080Z","iopub.status.idle":"2024-05-06T17:45:13.125939Z","shell.execute_reply":"2024-05-06T17:45:13.124998Z","shell.execute_reply.started":"2024-05-06T17:45:13.106322Z"},"trusted":true},"outputs":[],"source":["# Define Early Stopping callback\n","early_stop_callback = EarlyStopping(\n","   monitor='val_loss',\n","   patience=hyp['early_stopping_patience'],\n","   verbose=True,\n","   mode='min'\n",")\n","\n","# Define Model Checkpoint callback\n","checkpoint_callback = ModelCheckpoint(\n","    monitor='val_loss',\n","    dirpath='checkpoints/',\n","    filename=f\"{hyp['arch']}_best_model\",\n","    save_top_k=1,\n","    mode='min'\n",")"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T17:45:13.127824Z","iopub.status.busy":"2024-05-06T17:45:13.127250Z","iopub.status.idle":"2024-05-06T17:45:20.615218Z","shell.execute_reply":"2024-05-06T17:45:20.614224Z","shell.execute_reply.started":"2024-05-06T17:45:13.127784Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["wandb.login()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T17:45:20.617301Z","iopub.status.busy":"2024-05-06T17:45:20.616620Z","iopub.status.idle":"2024-05-06T17:45:20.703339Z","shell.execute_reply":"2024-05-06T17:45:20.702374Z","shell.execute_reply.started":"2024-05-06T17:45:20.617263Z"},"trusted":true},"outputs":[],"source":["# Set up Weights & Biases logging\n","wandb_logger = pl.loggers.wandb.WandbLogger(project=\"rai_ablation_study\", name=f\"{hyp['arch']}_training\")"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T17:45:20.704801Z","iopub.status.busy":"2024-05-06T17:45:20.704520Z","iopub.status.idle":"2024-05-06T17:45:21.530012Z","shell.execute_reply":"2024-05-06T17:45:21.529280Z","shell.execute_reply.started":"2024-05-06T17:45:20.704776Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b13a91a4bcfa465c850a9884770fef37","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/14.2M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Initialize model\n","model = PLModel(hyp['arch'], num_classes=100)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T17:45:21.531339Z","iopub.status.busy":"2024-05-06T17:45:21.531039Z","iopub.status.idle":"2024-05-06T17:45:22.120842Z","shell.execute_reply":"2024-05-06T17:45:22.120073Z","shell.execute_reply.started":"2024-05-06T17:45:21.531314Z"},"trusted":true},"outputs":[],"source":["# Initialize Lightning Trainer\n","trainer = pl.Trainer(\n","    max_epochs=hyp['epochs'], \n","    precision='16-mixed', # Use mixed precision training\n","    callbacks=[early_stop_callback, checkpoint_callback],\n","    logger=wandb_logger\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T17:45:22.122537Z","iopub.status.busy":"2024-05-06T17:45:22.122093Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlawjarp\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>./wandb/run-20240506_174522-voqliwq8</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/lawjarp/rai_ablation_study/runs/voqliwq8' target=\"_blank\">mobilenetv2_100_training</a></strong> to <a href='https://wandb.ai/lawjarp/rai_ablation_study' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/lawjarp/rai_ablation_study' target=\"_blank\">https://wandb.ai/lawjarp/rai_ablation_study</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/lawjarp/rai_ablation_study/runs/voqliwq8' target=\"_blank\">https://wandb.ai/lawjarp/rai_ablation_study/runs/voqliwq8</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /kaggle/working/checkpoints exists and is not empty.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a95a7d9036c40de9820ae2bed44710c","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Start training\n","trainer.fit(model, train_loader, val_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["csv_path = 'all_models_metrics_df.csv'\n","if not os.path.exists(csv_path):\n","    columns = ['model_name', 'accuracy_avg', 'precision_avg', 'recall_avg', 'f1_avg']\n","    for i in range(100):\n","        columns.append(f\"{label_to_class[i]}_precision\")\n","        columns.append(f\"{label_to_class[i]}_recall\")        \n","        columns.append(f\"{label_to_class[i]}_f1\")\n","    metrics_df = pd.DataFrame(columns=columns)\n","    metrics_df.to_csv(csv_path, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, precision_recall_fscore_support\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","model = PLModel.load_from_checkpoint(f\"./checkpoints/{hyp['arch']}_best_model.ckpt\", name=hyp['arch'], num_classes=100)\n","\n","\n","device = hyp['device']\n","model = model.to(device)\n","model.eval()\n","\n","true_labels = []\n","pred_labels = []\n","\n","with torch.no_grad():\n","    for images, labels in val_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","\n","        true_labels.extend(labels.cpu().numpy())\n","        pred_labels.extend(predicted.cpu().numpy())\n","\n","cr = classification_report(true_labels, pred_labels, output_dict=True)\n","\n","# Calculate confusion matrix\n","cm = confusion_matrix(true_labels, pred_labels)\n","\n","class_labels = [label_to_class[label] for label in range(len(label_to_class))]\n","# Convert confusion matrix to DataFrame for visualization\n","cm_df = pd.DataFrame(cm, index=class_labels, columns=class_labels)\n","cm_df.to_csv(f\"{hyp['arch']}_cf.csv\", index=False)\n","\n","# Get metrics from classification report\n","new_row = {}\n","new_row['model_name'] = hyp['arch']\n","new_row['accuracy_avg'] = cr['accuracy']\n","new_row['precision_avg'] = cr['macro avg']['precision']\n","new_row['recall_avg'] = cr['macro avg']['recall']\n","new_row['f1_avg'] = cr['macro avg']['f1-score']\n","for i in range(100):\n","    new_row[f\"{label_to_class[i]}_precision\"] = cr[str(i)]['precision']\n","    new_row[f\"{label_to_class[i]}_recall\"] = cr[str(i)]['recall']\n","    new_row[f\"{label_to_class[i]}_f1\"] = cr[str(i)]['f1-score']\n","    \n","df = pd.read_csv(csv_path)\n","df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n","df.to_csv(csv_path, index=False)\n","\n","total_params = sum(p.numel() for p in model.parameters())\n","\n","# Upload metrics and confusion matrix to wandb\n","table = wandb.Table(columns=[\"Model Name\", \"Model Params\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n","table.add_data(hyp['arch'], total_params, new_row['accuracy_avg'], new_row['precision_avg'], new_row['recall_avg'], new_row['f1_avg'])\n","\n","wandb.log({\"Metrics\": table,})"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"markdown","metadata":{},"source":["## Test new images"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import json\n","label_mapping = json.load(open(\"./Labels.json\"))"]},{"cell_type":"markdown","metadata":{},"source":["# Define augmentations for validation (usually only basic augmentations without randomness)\n","transforms_ = A.Compose([\n","    A.Resize(224,224),\n","    A.Normalize(),\n","    ToTensorV2(),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = PLModel.load_from_checkpoint(f\"./checkpoints/resnet50_best_model.ckpt\", name='resnet50', num_classes=100)\n","model = model.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["im_path = '/kaggle/input/imagenet100/val.X/n01484850/ILSVRC2012_val_00002338.JPEG'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_preds(model, image_path):\n","    model.eval()\n","    im = Image.open(image_path)\n","    im = im.convert('RGB')\n","    img = transforms_(image=np.array(im))['image']\n","    img = img.unsqueeze(0)\n","    out = model(img.cuda())\n","    _, predicted = torch.max(out, 1)\n","    predicted = predicted.item()\n","    plt.imshow(im)\n","    plt.show()\n","    print(\"Class: \", label_mapping[label_to_class[predicted]])\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":1500837,"sourceId":2491748,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
