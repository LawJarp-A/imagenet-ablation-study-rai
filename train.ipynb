{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2491748,"sourceType":"datasetVersion","datasetId":1500837}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport json\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, random_split\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.optim.lr_scheduler import OneCycleLR\n\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport timm\n\nimport wandb\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateFinder\nfrom torchmetrics import Accuracy\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T17:43:17.929841Z","iopub.execute_input":"2024-05-06T17:43:17.930184Z","iopub.status.idle":"2024-05-06T17:43:30.229241Z","shell.execute_reply.started":"2024-05-06T17:43:17.930145Z","shell.execute_reply":"2024-05-06T17:43:30.228422Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Consolidate data","metadata":{}},{"cell_type":"code","source":"def create_dataframe_from_folders(folder_list):\n    data = {'image_path': [], 'class': []}\n\n    for folder in tqdm(folder_list):\n        for root, dirs, files in os.walk(folder):\n            for file in files:\n                if file.endswith('.JPEG'):\n                    ts_file_path = os.path.join(root, file)\n                    data['image_path'].append(ts_file_path)\n                    data['class'].append(os.path.basename(root))\n\n    df = pd.DataFrame(data)\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-05-06T17:43:30.231135Z","iopub.execute_input":"2024-05-06T17:43:30.231586Z","iopub.status.idle":"2024-05-06T17:43:30.238294Z","shell.execute_reply.started":"2024-05-06T17:43:30.231553Z","shell.execute_reply":"2024-05-06T17:43:30.237332Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain_df = create_dataframe_from_folders(['/kaggle/input/imagenet100/train.X1', '/kaggle/input/imagenet100/train.X2', '/kaggle/input/imagenet100/train.X3', '/kaggle/input/imagenet100/train.X4'])\nval_df = create_dataframe_from_folders(['/kaggle/input/imagenet100/val.X'])\nprint('Number of Training Samples', len(train_df))\nprint('Number of unique clases: ', train_df['class'].nunique())\nprint()\nprint('Number of Validation Samples', len(val_df))","metadata":{"execution":{"iopub.status.busy":"2024-05-06T17:43:30.239473Z","iopub.execute_input":"2024-05-06T17:43:30.239850Z","iopub.status.idle":"2024-05-06T17:45:05.255283Z","shell.execute_reply.started":"2024-05-06T17:43:30.239817Z","shell.execute_reply":"2024-05-06T17:45:05.254001Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"100%|██████████| 4/4 [01:33<00:00, 23.36s/it]\n100%|██████████| 1/1 [00:01<00:00,  1.53s/it]","output_type":"stream"},{"name":"stdout","text":"Number of Training Samples 130000\nNumber of unique clases:  100\n\nNumber of Validation Samples 5000\nCPU times: user 950 ms, sys: 1.25 s, total: 2.2 s\nWall time: 1min 35s\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-06T17:45:05.257535Z","iopub.execute_input":"2024-05-06T17:45:05.257824Z","iopub.status.idle":"2024-05-06T17:45:05.271490Z","shell.execute_reply.started":"2024-05-06T17:45:05.257798Z","shell.execute_reply":"2024-05-06T17:45:05.270582Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                          image_path      class\n0  /kaggle/input/imagenet100/train.X1/n01531178/n...  n01531178\n1  /kaggle/input/imagenet100/train.X1/n01531178/n...  n01531178\n2  /kaggle/input/imagenet100/train.X1/n01531178/n...  n01531178\n3  /kaggle/input/imagenet100/train.X1/n01531178/n...  n01531178\n4  /kaggle/input/imagenet100/train.X1/n01531178/n...  n01531178","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/imagenet100/train.X1/n01531178/n...</td>\n      <td>n01531178</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/imagenet100/train.X1/n01531178/n...</td>\n      <td>n01531178</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/imagenet100/train.X1/n01531178/n...</td>\n      <td>n01531178</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/imagenet100/train.X1/n01531178/n...</td>\n      <td>n01531178</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/imagenet100/train.X1/n01531178/n...</td>\n      <td>n01531178</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"val_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-06T17:45:05.272665Z","iopub.execute_input":"2024-05-06T17:45:05.273006Z","iopub.status.idle":"2024-05-06T17:45:05.282281Z","shell.execute_reply.started":"2024-05-06T17:45:05.272975Z","shell.execute_reply":"2024-05-06T17:45:05.281345Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                          image_path      class\n0  /kaggle/input/imagenet100/val.X/n01531178/ILSV...  n01531178\n1  /kaggle/input/imagenet100/val.X/n01531178/ILSV...  n01531178\n2  /kaggle/input/imagenet100/val.X/n01531178/ILSV...  n01531178\n3  /kaggle/input/imagenet100/val.X/n01531178/ILSV...  n01531178\n4  /kaggle/input/imagenet100/val.X/n01531178/ILSV...  n01531178","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/imagenet100/val.X/n01531178/ILSV...</td>\n      <td>n01531178</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/imagenet100/val.X/n01531178/ILSV...</td>\n      <td>n01531178</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/imagenet100/val.X/n01531178/ILSV...</td>\n      <td>n01531178</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/imagenet100/val.X/n01531178/ILSV...</td>\n      <td>n01531178</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/imagenet100/val.X/n01531178/ILSV...</td>\n      <td>n01531178</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class_to_label = {class_name: label for label, class_name in enumerate(train_df['class'].unique())}\nlabel_to_class = {label: class_name for class_name, label in class_to_label.items()}","metadata":{"execution":{"iopub.status.busy":"2024-05-06T17:45:05.283315Z","iopub.execute_input":"2024-05-06T17:45:05.283622Z","iopub.status.idle":"2024-05-06T17:45:05.300952Z","shell.execute_reply.started":"2024-05-06T17:45:05.283593Z","shell.execute_reply":"2024-05-06T17:45:05.300191Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Define Augmentations","metadata":{}},{"cell_type":"code","source":"hyp = {\n    'image_size': 224,\n    'batch_size': 128,\n    'epochs': 15, \n    'arch': 'mobilenetv2_100',\n    'num_classes': 100,\n    'early_stopping_patience': 7,\n    'device': torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-06T17:45:05.302001Z","iopub.execute_input":"2024-05-06T17:45:05.302280Z","iopub.status.idle":"2024-05-06T17:45:05.330497Z","shell.execute_reply.started":"2024-05-06T17:45:05.302258Z","shell.execute_reply":"2024-05-06T17:45:05.329616Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Define a set of augmentations for training\ntrain_transform = A.Compose([\n    A.Resize(224,224),  # Resize images to a common size\n    A.HorizontalFlip(p=0.5),  # Apply horizontal flip with a probability of 0.5\n    A.VerticalFlip(p=0.5),  # Apply vertical flip with a probability of 0.5\n    A.RandomRotate90(p=0.5),  # Randomly rotate the image by 90 degrees\n    A.RandomBrightnessContrast(p=0.2),  # Adjust brightness and contrast\n    A.GaussNoise(p=0.2),  # Add random Gaussian noise\n    A.Normalize(),  # Normalize pixel values to be in the range [0, 1]\n    ToTensorV2(),  # Convert the image to a PyTorch tensor\n])\n\n# Define augmentations for validation (usually only basic augmentations without randomness)\nval_transform = A.Compose([\n    A.Resize(224,224),\n    A.Normalize(),\n    ToTensorV2(),\n])","metadata":{"execution":{"iopub.status.busy":"2024-05-06T17:45:05.331491Z","iopub.execute_input":"2024-05-06T17:45:05.331725Z","iopub.status.idle":"2024-05-06T17:45:05.339418Z","shell.execute_reply.started":"2024-05-06T17:45:05.331705Z","shell.execute_reply":"2024-05-06T17:45:05.338531Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Define PyTorch Dataset","metadata":{}},{"cell_type":"code","source":"class CustomImageNetDataset(torch.utils.data.Dataset):\n    def __init__(self, df, transform=None):\n        self.data = df\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_name = self.data.iloc[idx, 0]\n        image = Image.open(img_name)\n        image = image.convert('RGB')\n        label = self.data.iloc[idx, 1]\n        label = class_to_label[label]\n        \n        if self.transform:\n            image = self.transform(image=np.array(image))['image']\n\n        return image, label\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T17:45:05.340485Z","iopub.execute_input":"2024-05-06T17:45:05.340717Z","iopub.status.idle":"2024-05-06T17:45:05.349842Z","shell.execute_reply.started":"2024-05-06T17:45:05.340696Z","shell.execute_reply":"2024-05-06T17:45:05.349039Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Define Model","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\n\nclass CustomModel(nn.Module):\n    def __init__(self, model_name, num_classes, pretrained=True):\n        super(CustomModel, self).__init__()\n        # Load the base model\n        self.base_model = timm.create_model(model_name, pretrained=pretrained, num_classes=0)\n        \n        # Modify the classification head\n        in_features = self.base_model.num_features\n        self.classifier = nn.Sequential(\n            nn.Linear(in_features, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(512, num_classes),\n            nn.Softmax(dim=1)  # Apply softmax activation along the class dimension\n        )\n\n    def forward(self, x):\n        # Forward pass through the base model\n        features = self.base_model(x)\n        \n        # Forward pass through the classifier\n        output = self.classifier(features)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2024-05-06T17:45:05.354085Z","iopub.execute_input":"2024-05-06T17:45:05.354389Z","iopub.status.idle":"2024-05-06T17:45:05.361869Z","shell.execute_reply.started":"2024-05-06T17:45:05.354366Z","shell.execute_reply":"2024-05-06T17:45:05.360955Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Ready the data","metadata":{}},{"cell_type":"code","source":"train_dataset = CustomImageNetDataset(train_df, transform=train_transform)\nval_dataset = CustomImageNetDataset(val_df, transform=val_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=hyp['batch_size'], shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=hyp['batch_size'], shuffle=False, num_workers=4, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T17:45:05.362848Z","iopub.execute_input":"2024-05-06T17:45:05.363127Z","iopub.status.idle":"2024-05-06T17:45:05.375322Z","shell.execute_reply.started":"2024-05-06T17:45:05.363105Z","shell.execute_reply":"2024-05-06T17:45:05.374489Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Perform a sanity check on the data loaders\ndef check_data_loader(loader):\n    for batch_idx, (images, labels) in enumerate(loader):\n        print(f\"Batch {batch_idx + 1}:\")\n        print(\"Image shape:\", images.shape)\n        print(\"Label shape:\", labels.shape)\n        print(\"\\n\")\n        \n        # Stop after printing a few batches\n        if batch_idx == 2:\n            break\n\n# Perform sanity check on train_loader\nprint(\"Train DataLoader Sanity Check:\")\ncheck_data_loader(train_loader)\n\n# Perform sanity check on val_loader\nprint(\"Validation DataLoader Sanity Check:\")\ncheck_data_loader(val_loader)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T17:45:05.376304Z","iopub.execute_input":"2024-05-06T17:45:05.376614Z","iopub.status.idle":"2024-05-06T17:45:13.091297Z","shell.execute_reply.started":"2024-05-06T17:45:05.376591Z","shell.execute_reply":"2024-05-06T17:45:13.090131Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Train DataLoader Sanity Check:\nBatch 1:\nImage shape: torch.Size([128, 3, 224, 224])\nLabel shape: torch.Size([128])\n\n\nBatch 2:\nImage shape: torch.Size([128, 3, 224, 224])\nLabel shape: torch.Size([128])\n\n\nBatch 3:\nImage shape: torch.Size([128, 3, 224, 224])\nLabel shape: torch.Size([128])\n\n\nValidation DataLoader Sanity Check:\nBatch 1:\nImage shape: torch.Size([128, 3, 224, 224])\nLabel shape: torch.Size([128])\n\n\nBatch 2:\nImage shape: torch.Size([128, 3, 224, 224])\nLabel shape: torch.Size([128])\n\n\nBatch 3:\nImage shape: torch.Size([128, 3, 224, 224])\nLabel shape: torch.Size([128])\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Train with PyTorch Lightning","metadata":{}},{"cell_type":"code","source":"class PLModel(pl.LightningModule):\n    def __init__(self, name, num_classes, learning_rate=1e-3):\n        super().__init__()\n        self.name = name\n        self.num_classes = num_classes\n        self.learning_rate = learning_rate\n        \n        # Define your model\n        self.model = CustomModel(name, num_classes) # You need to define your model here\n        \n        # Loss function\n        self.loss_fn = nn.CrossEntropyLoss()\n        \n        # Metrics\n        self.train_acc = Accuracy('multiclass', num_classes=num_classes)\n        self.valid_acc = Accuracy('multiclass', num_classes=num_classes)\n        \n    def forward(self, x):\n        return self.model(x)\n    \n    def configure_optimizers(self):\n            optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n            scheduler = OneCycleLR(optimizer, max_lr=self.learning_rate, steps_per_epoch=len(train_loader), epochs=self.trainer.max_epochs)\n            return {\n                'optimizer': optimizer,\n#                 'lr_scheduler': {\n#                     'scheduler': scheduler,\n#                     'interval': 'step'\n#                 }\n            }\n\n    \n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = self.loss_fn(logits, y)\n        self.log('train_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n        self.log('train_acc', self.train_acc(logits, y), on_epoch=True, logger=True)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = self.loss_fn(logits, y)\n        self.log('val_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n        self.log('val_acc', self.valid_acc(logits, y), on_epoch=True, logger=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T17:45:13.092710Z","iopub.execute_input":"2024-05-06T17:45:13.093023Z","iopub.status.idle":"2024-05-06T17:45:13.104951Z","shell.execute_reply.started":"2024-05-06T17:45:13.092994Z","shell.execute_reply":"2024-05-06T17:45:13.103987Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Define Early Stopping callback\nearly_stop_callback = EarlyStopping(\n   monitor='val_loss',\n   patience=hyp['early_stopping_patience'],\n   verbose=True,\n   mode='min'\n)\n\n# Define Model Checkpoint callback\ncheckpoint_callback = ModelCheckpoint(\n    monitor='val_loss',\n    dirpath='checkpoints/',\n    filename=f\"{hyp['arch']}_best_model\",\n    save_top_k=1,\n    mode='min'\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T17:45:13.106080Z","iopub.execute_input":"2024-05-06T17:45:13.106344Z","iopub.status.idle":"2024-05-06T17:45:13.125939Z","shell.execute_reply.started":"2024-05-06T17:45:13.106322Z","shell.execute_reply":"2024-05-06T17:45:13.124998Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"wandb.login()","metadata":{"execution":{"iopub.status.busy":"2024-05-06T17:45:13.127250Z","iopub.execute_input":"2024-05-06T17:45:13.127824Z","iopub.status.idle":"2024-05-06T17:45:20.615218Z","shell.execute_reply.started":"2024-05-06T17:45:13.127784Z","shell.execute_reply":"2024-05-06T17:45:20.614224Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# Set up Weights & Biases logging\nwandb_logger = pl.loggers.wandb.WandbLogger(project=\"rai_ablation_study\", name=f\"{hyp['arch']}_training\")","metadata":{"execution":{"iopub.status.busy":"2024-05-06T17:45:20.616620Z","iopub.execute_input":"2024-05-06T17:45:20.617301Z","iopub.status.idle":"2024-05-06T17:45:20.703339Z","shell.execute_reply.started":"2024-05-06T17:45:20.617263Z","shell.execute_reply":"2024-05-06T17:45:20.702374Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Initialize model\nmodel = PLModel(hyp['arch'], num_classes=100)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T17:45:20.704520Z","iopub.execute_input":"2024-05-06T17:45:20.704801Z","iopub.status.idle":"2024-05-06T17:45:21.530012Z","shell.execute_reply.started":"2024-05-06T17:45:20.704776Z","shell.execute_reply":"2024-05-06T17:45:21.529280Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/14.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b13a91a4bcfa465c850a9884770fef37"}},"metadata":{}}]},{"cell_type":"code","source":"# Initialize Lightning Trainer\ntrainer = pl.Trainer(\n    max_epochs=hyp['epochs'], \n    precision='16-mixed', # Use mixed precision training\n    callbacks=[early_stop_callback, checkpoint_callback],\n    logger=wandb_logger\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T17:45:21.531039Z","iopub.execute_input":"2024-05-06T17:45:21.531339Z","iopub.status.idle":"2024-05-06T17:45:22.120842Z","shell.execute_reply.started":"2024-05-06T17:45:21.531314Z","shell.execute_reply":"2024-05-06T17:45:22.120073Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Start training\ntrainer.fit(model, train_loader, val_loader)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T17:45:22.122093Z","iopub.execute_input":"2024-05-06T17:45:22.122537Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlawjarp\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>./wandb/run-20240506_174522-voqliwq8</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/lawjarp/rai_ablation_study/runs/voqliwq8' target=\"_blank\">mobilenetv2_100_training</a></strong> to <a href='https://wandb.ai/lawjarp/rai_ablation_study' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/lawjarp/rai_ablation_study' target=\"_blank\">https://wandb.ai/lawjarp/rai_ablation_study</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/lawjarp/rai_ablation_study/runs/voqliwq8' target=\"_blank\">https://wandb.ai/lawjarp/rai_ablation_study/runs/voqliwq8</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /kaggle/working/checkpoints exists and is not empty.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a95a7d9036c40de9820ae2bed44710c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"code","source":"csv_path = 'all_models_metrics_df.csv'\nif not os.path.exists(csv_path):\n    columns = ['model_name', 'accuracy_avg', 'precision_avg', 'recall_avg', 'f1_avg']\n    for i in range(100):\n        columns.append(f\"{label_to_class[i]}_precision\")\n        columns.append(f\"{label_to_class[i]}_recall\")        \n        columns.append(f\"{label_to_class[i]}_f1\")\n    metrics_df = pd.DataFrame(columns=columns)\n    metrics_df.to_csv(csv_path, index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls -la ./checkpoints","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rm all_models_metrics_df.csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, precision_recall_fscore_support\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsave_table_path = f\"{hyp['arch']}_val.csv\"\n# model.load_state_dict(f\"./checkpoints/{hyp['arch']}_best_model.ckpt\")\n# model = PLModel(hyp['arch'], num_classes=100)\nmodel = PLModel.load_from_checkpoint(f\"./checkpoints/{hyp['arch']}_best_model.ckpt\", name=hyp['arch'], num_classes=100)\n\n\ndevice = hyp['device']\nmodel = model.to(device)\nmodel.eval()\n\ntrue_labels = []\npred_labels = []\n\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n\n        true_labels.extend(labels.cpu().numpy())\n        pred_labels.extend(predicted.cpu().numpy())\n\ncr = classification_report(true_labels, pred_labels, output_dict=True)\n\n# Calculate confusion matrix\ncm = confusion_matrix(true_labels, pred_labels)\n\nclass_labels = [label_to_class[label] for label in range(len(label_to_class))]\n# Convert confusion matrix to DataFrame for visualization\ncm_df = pd.DataFrame(cm, index=class_labels, columns=class_labels)\ncm_df.to_csv(f\"{hyp['arch']}_cf.csv\", index=False)\n\n# Get metrics from classification report\nnew_row = {}\nnew_row['model_name'] = hyp['arch']\nnew_row['accuracy_avg'] = cr['accuracy']\nnew_row['precision_avg'] = cr['macro avg']['precision']\nnew_row['recall_avg'] = cr['macro avg']['recall']\nnew_row['f1_avg'] = cr['macro avg']['f1-score']\nfor i in range(100):\n    new_row[f\"{label_to_class[i]}_precision\"] = cr[str(i)]['precision']\n    new_row[f\"{label_to_class[i]}_recall\"] = cr[str(i)]['recall']\n    new_row[f\"{label_to_class[i]}_f1\"] = cr[str(i)]['f1-score']\n    \ndf = pd.read_csv(csv_path)\ndf = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\ndf.to_csv(csv_path, index=False)\n\ntotal_params = sum(p.numel() for p in model.parameters())\n\n# Upload metrics and confusion matrix to wandb\ntable = wandb.Table(columns=[\"Model Name\", \"Model Params\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\ntable.add_data(hyp['arch'], total_params, new_row['accuracy_avg'], new_row['precision_avg'], new_row['recall_avg'], new_row['f1_avg'])\n\nwandb.log({\"Metrics\": table,})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}